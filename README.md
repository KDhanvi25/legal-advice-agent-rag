âš–ï¸ RAG-based Legal Q&A System for Indian Law

A Retrieval-Augmented Generation (RAG) system designed to answer Indian law questions with relevant context and clear legal reasoning.
The system retrieves sections from the IPC, CrPC, Constitution of India, and Nyaaya FAQs, then uses Microsoft Phiâ€‘2 (2.7B) to generate lawyerâ€‘style answers.

ğŸ“‚ Project Structure
.
â”œâ”€â”€ app.py                 # Streamlit UI for interactive querying
â”œâ”€â”€ build_index.py         # Builds FAISS index from formatted legal text files
â”œâ”€â”€ evaluate_agent.py      # Automated evaluation on benchmark questions
â”œâ”€â”€ query_agent.py         # CLI interface for asking legal questions
â”œâ”€â”€ requirements.txt       # Python dependencies (see note for Streamlit)
â”œâ”€â”€ legal_faiss.index      # FAISS index of embedded chunks
â”œâ”€â”€ legal_chunks.pkl       # Pickled chunks and their sources
â”œâ”€â”€ evaluation_results.csv # Saved evaluation metrics
â”œâ”€â”€ results.txt            # Console output from an evaluation run
â”œâ”€â”€ pdfs/                  # Raw legal documents (PDFs)
â””â”€â”€ formatted_txts/        # Cleaned & formatted text files for indexing


ğŸš€ Features
PDF â†’ text ingestion (curated statutes + FAQs)
Embeddings with all-MiniLM-L6-v2
Dense retrieval via FAISS
LLM answers with Microsoft Phiâ€‘2
Two interfaces: Streamlit app + CLI
Evaluation: response length, cosine similarity, and legal-term coverage


ğŸ› ï¸ Installation
git clone https://github.com/yourusername/legal-advice-agent.git
cd legal-advice-agent
pip install -r requirements.txt
# For the web app UI:
pip install streamlit


ğŸ“Š Build the FAISS Index
Put cleaned text files in formatted_txts/ and run:
python build_index.py

This creates:
legal_faiss.index
legal_chunks.pkl

ğŸ’¬ Run the Agent
streamlit run app.py
Open http://localhost:8501, then ask:

â€œWhat is anticipatory bail and when can it be granted?â€

â€œWhat are the rights of a daughter in ancestral property?â€

ğŸ“ˆ Evaluation
python evaluate_agent.py

Outputs:
evaluation_results.csv (perâ€‘query metrics)
Console summary (example in results.txt)

ğŸ“Š Results (Exact Averages from 20 Benchmark Questions)
Average Response Length: 345.1 words
Average Cosine Similarity (Q â†” A): 0.689
Average Legal-Term Coverage: 1.4 terms/answer
(terms counted from: IPC, CrPC, Section, Article, Act, Constitution, Court)
These metrics show consistent, contextâ€‘aware answers with legal terminology appearing regularly in responses.

ğŸ“¦ Requirements
From requirements.txt:
torch
sentence-transformers
faiss-gpu
transformers
accelerate

If you use the web app:
streamlit

ğŸ“š Sources Used
Indian Penal Code (IPC)
Criminal Procedure Code (CrPC)
Constitution of India
Nyaaya FAQs (https://nyaaya.org/question-bank/)

âš ï¸ Disclaimer
This project is for informational purposes only and does not constitute legal advice. Please consult a qualified lawyer for actual legal matters.